{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers[torch]\n!pip install sentencepiece\n!pip install datasets\n!pip install evaluate","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-07-29T10:19:45.635019Z","iopub.execute_input":"2023-07-29T10:19:45.635350Z","iopub.status.idle":"2023-07-29T10:20:35.179325Z","shell.execute_reply.started":"2023-07-29T10:19:45.635321Z","shell.execute_reply":"2023-07-29T10:20:35.178151Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers[torch] in /opt/conda/lib/python3.10/site-packages (4.30.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.16.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (6.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2023.6.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2.31.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.13.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.3.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (4.65.0)\nRequirement already satisfied: torch!=1.12.0,>=1.9 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2.0.0)\nRequirement already satisfied: accelerate>=0.20.2 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.20.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.20.2->transformers[torch]) (5.9.3)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers[torch]) (2023.6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers[torch]) (4.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers[torch]) (3.0.9)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (2023.5.7)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch!=1.12.0,>=1.9->transformers[torch]) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch!=1.12.0,>=1.9->transformers[torch]) (1.3.0)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (0.1.99)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.1.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.23.5)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (11.0.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.6)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (1.5.3)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.65.0)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.2.0)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.14)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2023.6.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.8.4)\nRequirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.16.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.18.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (3.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.12.2)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.0.9)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2023.5.7)\nRequirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\nCollecting evaluate\n  Downloading evaluate-0.4.0-py3-none-any.whl (81 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.1.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.23.5)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.6)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.5.3)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.65.0)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.2.0)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.14)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2023.6.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.16.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.18.0)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (11.0.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.8.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.12.2)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2023.5.7)\nRequirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\nInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import random\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\n\n# datasets\nfrom datasets import Dataset\nfrom datasets import DatasetDict\nfrom datasets import load_metric\nfrom datasets import load_dataset\n\n# transformers\nfrom transformers import Trainer\nfrom transformers import AutoModel\nfrom transformers import AutoTokenizer\nfrom transformers import DataCollatorWithPadding\nfrom transformers import TrainingArguments\nfrom transformers import AutoModelForSeq2SeqLM\nfrom transformers import AutoModelForSequenceClassification\nfrom transformers import EarlyStoppingCallback\nfrom transformers import IntervalStrategy\n\nimport torch\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import TensorDataset\n\nfrom sklearn.metrics import accuracy_score, f1_score\n\nimport evaluate","metadata":{"execution":{"iopub.status.busy":"2023-07-29T10:45:14.547572Z","iopub.execute_input":"2023-07-29T10:45:14.547954Z","iopub.status.idle":"2023-07-29T10:45:29.002703Z","shell.execute_reply.started":"2023-07-29T10:45:14.547918Z","shell.execute_reply":"2023-07-29T10:45:29.001799Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"SEED = 111\n\n# Set the random seed for Python to SEED\nrandom.seed(SEED)\n\n# Set the random seed for numpy to SEED\nnp.random.seed(SEED)\n\n# Set the random seed for torch to SEED\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed_all(SEED)","metadata":{"execution":{"iopub.status.busy":"2023-07-29T10:45:37.086561Z","iopub.execute_input":"2023-07-29T10:45:37.086929Z","iopub.status.idle":"2023-07-29T10:45:37.096375Z","shell.execute_reply.started":"2023-07-29T10:45:37.086899Z","shell.execute_reply":"2023-07-29T10:45:37.095434Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train_path = \"/kaggle/input/amazon/train.csv\"\ntest_path = \"/kaggle/input/amazon/test.csv\"\nvalid_path = \"/kaggle/input/amazon/valid.csv\"","metadata":{"execution":{"iopub.status.busy":"2023-07-29T10:45:39.685102Z","iopub.execute_input":"2023-07-29T10:45:39.685460Z","iopub.status.idle":"2023-07-29T10:45:39.690094Z","shell.execute_reply.started":"2023-07-29T10:45:39.685431Z","shell.execute_reply":"2023-07-29T10:45:39.689157Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(train_path)\ntest_df = pd.read_csv(test_path)\nvalid_df = pd.read_csv(valid_path)","metadata":{"execution":{"iopub.status.busy":"2023-07-29T10:45:41.344766Z","iopub.execute_input":"2023-07-29T10:45:41.345443Z","iopub.status.idle":"2023-07-29T10:45:52.728740Z","shell.execute_reply.started":"2023-07-29T10:45:41.345404Z","shell.execute_reply":"2023-07-29T10:45:52.727741Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train_df = train_df[train_df['stars'].isin([1, 2, 4, 5])]\ntrain_df = train_df[train_df['language'].isin(['en', 'de', 'fr', 'es'])]\n# train_df = train_df[train_df['language'].isin(['en'])]\n\ntest_df = test_df[test_df['stars'].isin([1, 2, 4, 5])]\ntest_df = test_df[test_df['language'].isin(['en', 'de', 'fr', 'es'])]\n# test_df = test_df[test_df['language'].isin(['en'])]\n\nvalid_df = valid_df[valid_df['stars'].isin([1, 2, 4, 5])]\ntest_df = test_df[test_df['language'].isin(['en', 'de', 'fr', 'es'])]\n# valid_df = valid_df[valid_df['language'].isin(['en'])]\n\n\ncolumns_to_drop = ['review_id', 'product_id', 'reviewer_id', 'product_category']\ntrain_df.drop(columns=columns_to_drop, inplace=True)\ntest_df.drop(columns=columns_to_drop, inplace=True)\nvalid_df.drop(columns=columns_to_drop, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-07-29T10:45:58.495935Z","iopub.execute_input":"2023-07-29T10:45:58.496287Z","iopub.status.idle":"2023-07-29T10:45:59.110179Z","shell.execute_reply.started":"2023-07-29T10:45:58.496258Z","shell.execute_reply":"2023-07-29T10:45:59.108914Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"num_rows_to_delete = 30000","metadata":{"execution":{"iopub.status.busy":"2023-07-29T10:46:03.916550Z","iopub.execute_input":"2023-07-29T10:46:03.916920Z","iopub.status.idle":"2023-07-29T10:46:03.921665Z","shell.execute_reply.started":"2023-07-29T10:46:03.916890Z","shell.execute_reply":"2023-07-29T10:46:03.920551Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# for lang in ['en']:\nfor lang in ['en', 'de', 'es', 'fr']:\n    for star in [1, 2, 4, 5]:\n        print(f'Language: {lang}, Stars: {star}')\n        print(f'Number of rows before: {len(train_df[(train_df[\"language\"] == lang) & (train_df[\"stars\"] == star)])}')\n        random_indices = np.random.choice(train_df[(train_df['language'] == lang) & (train_df['stars'] == star)].index, num_rows_to_delete, replace=False)\n        train_df.drop(index=random_indices, inplace=True)\n        print(f'Number of rows after: {len(train_df[(train_df[\"language\"] == lang) & (train_df[\"stars\"] == star)])}')","metadata":{"execution":{"iopub.status.busy":"2023-07-29T10:46:07.983776Z","iopub.execute_input":"2023-07-29T10:46:07.984128Z","iopub.status.idle":"2023-07-29T10:46:11.993225Z","shell.execute_reply.started":"2023-07-29T10:46:07.984098Z","shell.execute_reply":"2023-07-29T10:46:11.991875Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Language: en, Stars: 1\nNumber of rows before: 40000\nNumber of rows after: 10000\nLanguage: en, Stars: 2\nNumber of rows before: 40000\nNumber of rows after: 10000\nLanguage: en, Stars: 4\nNumber of rows before: 40000\nNumber of rows after: 10000\nLanguage: en, Stars: 5\nNumber of rows before: 40000\nNumber of rows after: 10000\nLanguage: de, Stars: 1\nNumber of rows before: 40000\nNumber of rows after: 10000\nLanguage: de, Stars: 2\nNumber of rows before: 40000\nNumber of rows after: 10000\nLanguage: de, Stars: 4\nNumber of rows before: 40000\nNumber of rows after: 10000\nLanguage: de, Stars: 5\nNumber of rows before: 40000\nNumber of rows after: 10000\nLanguage: es, Stars: 1\nNumber of rows before: 40000\nNumber of rows after: 10000\nLanguage: es, Stars: 2\nNumber of rows before: 40000\nNumber of rows after: 10000\nLanguage: es, Stars: 4\nNumber of rows before: 40000\nNumber of rows after: 10000\nLanguage: es, Stars: 5\nNumber of rows before: 40000\nNumber of rows after: 10000\nLanguage: fr, Stars: 1\nNumber of rows before: 40000\nNumber of rows after: 10000\nLanguage: fr, Stars: 2\nNumber of rows before: 40000\nNumber of rows after: 10000\nLanguage: fr, Stars: 4\nNumber of rows before: 40000\nNumber of rows after: 10000\nLanguage: fr, Stars: 5\nNumber of rows before: 40000\nNumber of rows after: 10000\n","output_type":"stream"}]},{"cell_type":"code","source":"def replace_mapping(df, label):\n    for i, r in df.iterrows():\n        if r[label] >= 4:\n            df.loc[i, label] = 1\n        else:\n            df.loc[i, label] = 0\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2023-07-29T10:46:17.155309Z","iopub.execute_input":"2023-07-29T10:46:17.155701Z","iopub.status.idle":"2023-07-29T10:46:17.161927Z","shell.execute_reply.started":"2023-07-29T10:46:17.155670Z","shell.execute_reply":"2023-07-29T10:46:17.160881Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"train_df = replace_mapping(train_df, 'stars')\ntest_df = replace_mapping(test_df, 'stars')\nvalid_df = replace_mapping(valid_df, 'stars')","metadata":{"execution":{"iopub.status.busy":"2023-07-29T10:46:19.135024Z","iopub.execute_input":"2023-07-29T10:46:19.135379Z","iopub.status.idle":"2023-07-29T10:47:27.544739Z","shell.execute_reply.started":"2023-07-29T10:46:19.135350Z","shell.execute_reply":"2023-07-29T10:47:27.543717Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"train_df.reset_index(drop=True, inplace=True)\ntest_df.reset_index(drop=True, inplace=True)\nvalid_df.reset_index(drop=True, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-07-29T10:47:35.096156Z","iopub.execute_input":"2023-07-29T10:47:35.096515Z","iopub.status.idle":"2023-07-29T10:47:35.101871Z","shell.execute_reply.started":"2023-07-29T10:47:35.096479Z","shell.execute_reply":"2023-07-29T10:47:35.100781Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"train_df.shape, test_df.shape, valid_df.shape","metadata":{"execution":{"iopub.status.busy":"2023-07-29T10:47:38.163714Z","iopub.execute_input":"2023-07-29T10:47:38.164133Z","iopub.status.idle":"2023-07-29T10:47:38.171969Z","shell.execute_reply.started":"2023-07-29T10:47:38.164102Z","shell.execute_reply":"2023-07-29T10:47:38.170975Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"((160000, 4), (16000, 4), (24000, 4))"},"metadata":{}}]},{"cell_type":"code","source":"print(train_df[\"stars\"].unique())\nprint(test_df[\"stars\"].unique())\nprint(valid_df[\"stars\"].unique())","metadata":{"execution":{"iopub.status.busy":"2023-07-29T10:47:40.152477Z","iopub.execute_input":"2023-07-29T10:47:40.152864Z","iopub.status.idle":"2023-07-29T10:47:40.162830Z","shell.execute_reply.started":"2023-07-29T10:47:40.152832Z","shell.execute_reply":"2023-07-29T10:47:40.161672Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"[0 1]\n[0 1]\n[0 1]\n","output_type":"stream"}]},{"cell_type":"code","source":"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2023-07-29T10:47:43.245058Z","iopub.execute_input":"2023-07-29T10:47:43.245413Z","iopub.status.idle":"2023-07-29T10:47:43.279381Z","shell.execute_reply.started":"2023-07-29T10:47:43.245383Z","shell.execute_reply":"2023-07-29T10:47:43.278260Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"def prepare_truncation(data_df, tokenizer, m, n):\n    # Create a tqdm progress bar for the loop\n    for i, r in tqdm(data_df.iterrows(), total=len(data_df), desc=\"Processing reviews\"):\n        tokenized_row = tokenizer.tokenize(r['review_body'])\n        if len(tokenized_row) > m+n:\n            data_df.loc[i, 'review_body'] = tokenizer.convert_tokens_to_string(tokenized_row[:m] + tokenized_row[-n:])\n\n    return data_df","metadata":{"execution":{"iopub.status.busy":"2023-07-29T10:47:45.754721Z","iopub.execute_input":"2023-07-29T10:47:45.755202Z","iopub.status.idle":"2023-07-29T10:47:45.761657Z","shell.execute_reply.started":"2023-07-29T10:47:45.755168Z","shell.execute_reply":"2023-07-29T10:47:45.760704Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"model_name = 'bert-base-multilingual-cased'\ntokenizer = AutoTokenizer.from_pretrained(model_name, num_labels=2)","metadata":{"execution":{"iopub.status.busy":"2023-07-29T10:47:48.175434Z","iopub.execute_input":"2023-07-29T10:47:48.175805Z","iopub.status.idle":"2023-07-29T10:47:49.858420Z","shell.execute_reply.started":"2023-07-29T10:47:48.175775Z","shell.execute_reply":"2023-07-29T10:47:49.857285Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a29e433aa5e4c00949a50545c7b1a22"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"954bc583997c454bb38b2ecd53976e5e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5aa7e7e400f74c63a52439dbced685e8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a285bbe289a54f97b8de714555c8b281"}},"metadata":{}}]},{"cell_type":"code","source":"N = 128\nM = 382\n# N = 64\n# M = 64","metadata":{"execution":{"iopub.status.busy":"2023-07-29T10:47:53.805149Z","iopub.execute_input":"2023-07-29T10:47:53.805500Z","iopub.status.idle":"2023-07-29T10:47:53.810375Z","shell.execute_reply.started":"2023-07-29T10:47:53.805472Z","shell.execute_reply":"2023-07-29T10:47:53.809364Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"train_df = prepare_truncation(train_df, tokenizer, M, N)\ntest_df = prepare_truncation(test_df, tokenizer, M, N)\nvalid_df = prepare_truncation(valid_df, tokenizer, M, N)","metadata":{"execution":{"iopub.status.busy":"2023-07-29T10:47:56.175865Z","iopub.execute_input":"2023-07-29T10:47:56.176223Z","iopub.status.idle":"2023-07-29T10:48:56.363502Z","shell.execute_reply.started":"2023-07-29T10:47:56.176194Z","shell.execute_reply":"2023-07-29T10:48:56.362555Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"Processing reviews:   2%|▏         | 2768/160000 [00:00<00:52, 2969.39it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (591 > 512). Running this sequence through the model will result in indexing errors\nProcessing reviews: 100%|██████████| 160000/160000 [00:47<00:00, 3335.67it/s]\nProcessing reviews: 100%|██████████| 16000/16000 [00:04<00:00, 3378.40it/s]\nProcessing reviews: 100%|██████████| 24000/24000 [00:07<00:00, 3217.30it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"train_ds = Dataset.from_pandas(train_df)\ntest_ds = Dataset.from_pandas(test_df)\nvalid_ds = Dataset.from_pandas(valid_df)\n\n\nen_only_dataset = DatasetDict()\n\nen_only_dataset['train'] = train_ds\nen_only_dataset['validation'] = valid_ds\nen_only_dataset['test'] = test_ds","metadata":{"execution":{"iopub.status.busy":"2023-07-29T10:49:36.556860Z","iopub.execute_input":"2023-07-29T10:49:36.557223Z","iopub.status.idle":"2023-07-29T10:49:36.689445Z","shell.execute_reply.started":"2023-07-29T10:49:36.557194Z","shell.execute_reply":"2023-07-29T10:49:36.688442Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"train_df.shape, test_df.shape, valid_df.shape","metadata":{"execution":{"iopub.status.busy":"2023-07-29T10:50:30.645657Z","iopub.execute_input":"2023-07-29T10:50:30.646413Z","iopub.status.idle":"2023-07-29T10:50:30.652704Z","shell.execute_reply.started":"2023-07-29T10:50:30.646380Z","shell.execute_reply":"2023-07-29T10:50:30.651799Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"((160000, 4), (16000, 4), (24000, 4))"},"metadata":{}}]},{"cell_type":"code","source":"# Preprocess function with labels\ndef preprocess_function(examples):\n    inputs = tokenizer(examples[\"review_body\"], truncation=True)\n    inputs[\"labels\"] = examples[\"stars\"]\n    return inputs\n\n# Tokenize the datasets\ntokenized_train = en_only_dataset[\"train\"].map(preprocess_function, batched=True)\ntokenized_validation = en_only_dataset[\"validation\"].map(preprocess_function, batched=True)\ntokenized_test = en_only_dataset[\"test\"].map(preprocess_function, batched=True)\n\n# Data collator for padding\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n\n# Load the model\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=5)\n\n# Load metrics outside the compute_metrics function\nload_accuracy = evaluate.load(\"accuracy\")\nload_f1 = evaluate.load(\"f1\")\n\n# Compute metrics function\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = np.argmax(logits, axis=-1)\n    accuracy = load_accuracy.compute(predictions=predictions, references=labels)[\"accuracy\"]\n    f1 = load_f1.compute(predictions=predictions, references=labels, average=\"weighted\")[\"f1\"]\n    return {\"accuracy\": accuracy, \"f1\": f1}","metadata":{"execution":{"iopub.status.busy":"2023-07-29T10:49:40.015096Z","iopub.execute_input":"2023-07-29T10:49:40.015523Z","iopub.status.idle":"2023-07-29T10:50:16.832903Z","shell.execute_reply.started":"2023-07-29T10:49:40.015481Z","shell.execute_reply":"2023-07-29T10:50:16.832001Z"},"trusted":true},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/160 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a2bbec0b85d341ac995a702caa1373bf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/24 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"edbfb95de3634554b50732fbb9374d11"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/16 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8add4be7bba940e49c51aabb942181a3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47f230196aac4aa68f5302ff525dc1e8"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2775ba3b8e7e46ffa0d67c54aea1eefd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.77k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"079ecaa1fa114cffa333c3cfd63075ce"}},"metadata":{}}]},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"./results\",\n    warmup_steps=10000,\n    optim=\"adamw_torch\",\n    num_train_epochs=2,\n    weight_decay=1e-4,\n    save_strategy=IntervalStrategy.STEPS,\n    evaluation_strategy=IntervalStrategy.STEPS,\n    eval_steps=500,\n    logging_strategy=IntervalStrategy.STEPS,\n    push_to_hub=False,\n    metric_for_best_model=\"f1\",\n    load_best_model_at_end=True,\n    save_total_limit=5,\n)\n\n# Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_train,\n    eval_dataset=tokenized_validation,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)","metadata":{"execution":{"iopub.status.busy":"2023-07-29T10:50:42.504767Z","iopub.execute_input":"2023-07-29T10:50:42.505243Z","iopub.status.idle":"2023-07-29T10:50:47.878058Z","shell.execute_reply.started":"2023-07-29T10:50:42.505194Z","shell.execute_reply":"2023-07-29T10:50:47.877092Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-07-29T10:50:51.510200Z","iopub.execute_input":"2023-07-29T10:50:51.510573Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.15.7 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.15.5"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20230729_105243-m2egooda</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/nlp-project-reichman/huggingface/runs/m2egooda' target=\"_blank\">dashing-snowball-1</a></strong> to <a href='https://wandb.ai/nlp-project-reichman/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/nlp-project-reichman/huggingface' target=\"_blank\">https://wandb.ai/nlp-project-reichman/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/nlp-project-reichman/huggingface/runs/m2egooda' target=\"_blank\">https://wandb.ai/nlp-project-reichman/huggingface/runs/m2egooda</a>"},"metadata":{}},{"name":"stderr","text":"You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2501' max='40000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 2501/40000 13:24 < 3:21:17, 3.10 it/s, Epoch 0.12/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>1.024800</td>\n      <td>0.599325</td>\n      <td>0.751875</td>\n      <td>0.751823</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.502500</td>\n      <td>0.584421</td>\n      <td>0.757500</td>\n      <td>0.748143</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>0.447400</td>\n      <td>0.441986</td>\n      <td>0.820875</td>\n      <td>0.820485</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>0.362400</td>\n      <td>0.515748</td>\n      <td>0.821167</td>\n      <td>0.820718</td>\n    </tr>\n  </tbody>\n</table><p>\n    <div>\n      \n      <progress value='2456' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2456/3000 01:33 < 00:20, 26.22 it/s]\n    </div>\n    "},"metadata":{}}]},{"cell_type":"code","source":"trainer.evaluate()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results = trainer.evaluate(eval_dataset=tokenized_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"file_name = 'uncased-92acc-2classes-128tokens'\nfile_name = f\"{model_name}_2classes_{N+M}tokens_{results['eval_f1']:.2f}f1\"\ntrainer.save_model(file_name)","metadata":{},"execution_count":null,"outputs":[]}]}