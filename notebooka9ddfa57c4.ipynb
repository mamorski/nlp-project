{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d93fef76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-09T17:54:05.488772Z",
     "iopub.status.busy": "2023-08-09T17:54:05.488364Z",
     "iopub.status.idle": "2023-08-09T17:54:52.133025Z",
     "shell.execute_reply": "2023-08-09T17:54:52.131888Z"
    },
    "id": "I0Gdjq43mLI-",
    "outputId": "a12c8764-a114-4685-85d1-e71810e9419b",
    "papermill": {
     "duration": 46.656929,
     "end_time": "2023-08-09T17:54:52.135530",
     "exception": false,
     "start_time": "2023-08-09T17:54:05.478601",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[torch] in /opt/conda/lib/python3.10/site-packages (4.30.2)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (3.12.2)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.16.4)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (1.23.5)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (21.3)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (6.0)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2023.6.3)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2.31.0)\r\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.13.3)\r\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.3.1)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (4.65.0)\r\n",
      "Requirement already satisfied: torch!=1.12.0,>=1.9 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2.0.0)\r\n",
      "Requirement already satisfied: accelerate>=0.20.2 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.20.3)\r\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.20.2->transformers[torch]) (5.9.3)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers[torch]) (2023.6.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers[torch]) (4.6.3)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers[torch]) (3.0.9)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (1.12)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (3.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (3.1.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (3.1.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (1.26.15)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (2023.5.7)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch!=1.12.0,>=1.9->transformers[torch]) (2.1.3)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch!=1.12.0,>=1.9->transformers[torch]) (1.3.0)\r\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (0.1.99)\r\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.1.0)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.23.5)\r\n",
      "Requirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (11.0.0)\r\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.6)\r\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (1.5.3)\r\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.31.0)\r\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.65.0)\r\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.2.0)\r\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.14)\r\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2023.6.0)\r\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.8.4)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.16.4)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\r\n",
      "Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.18.0)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (3.1.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.2)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.2)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.3)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.12.2)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.6.3)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.0.9)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.15)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2023.5.7)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\r\n",
      "Collecting evaluate\r\n",
      "  Downloading evaluate-0.4.0-py3-none-any.whl (81 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.1.0)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.23.5)\r\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.6)\r\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.5.3)\r\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.31.0)\r\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.65.0)\r\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.2.0)\r\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.14)\r\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2023.6.0)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.16.4)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\r\n",
      "Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.18.0)\r\n",
      "Requirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (11.0.0)\r\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.8.4)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.12.2)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (6.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.6.3)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.0.9)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.1.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.15)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2023.5.7)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.2)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\r\n",
      "Installing collected packages: evaluate\r\n",
      "Successfully installed evaluate-0.4.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers[torch]\n",
    "!pip install sentencepiece\n",
    "!pip install datasets\n",
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc1487b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-09T17:54:52.158602Z",
     "iopub.status.busy": "2023-08-09T17:54:52.157049Z",
     "iopub.status.idle": "2023-08-09T17:55:07.819631Z",
     "shell.execute_reply": "2023-08-09T17:55:07.818672Z"
    },
    "id": "SIyT2McYmLJA",
    "papermill": {
     "duration": 15.676421,
     "end_time": "2023-08-09T17:55:07.822090",
     "exception": false,
     "start_time": "2023-08-09T17:54:52.145669",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from tabulate import tabulate\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# datasets\n",
    "from datasets import Dataset\n",
    "from datasets import DatasetDict\n",
    "from datasets import load_metric\n",
    "from datasets import load_dataset\n",
    "\n",
    "# transformers\n",
    "from transformers import Trainer\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import TrainingArguments\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import IntervalStrategy\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58455be0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-09T17:55:07.843923Z",
     "iopub.status.busy": "2023-08-09T17:55:07.843635Z",
     "iopub.status.idle": "2023-08-09T17:55:07.857067Z",
     "shell.execute_reply": "2023-08-09T17:55:07.855793Z"
    },
    "papermill": {
     "duration": 0.026206,
     "end_time": "2023-08-09T17:55:07.858836",
     "exception": true,
     "start_time": "2023-08-09T17:55:07.832630",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ff0000; text-decoration-color: #ff0000\">╭──────────────────────────────────────────────────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> os.environ<span style=\"font-weight: bold\">[</span>“WANDB_DISABLED”<span style=\"font-weight: bold\">]</span> = “true”                                                            <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>            <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">▲</span>                                                                                     <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">SyntaxError: </span>invalid character <span style=\"color: #008000; text-decoration-color: #008000\">'“'</span> <span style=\"font-weight: bold\">(</span>U+201C<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[91m╭──────────────────────────────────────────────────────────────────────────────────────────────────╮\u001b[0m\n",
       "\u001b[91m│\u001b[0m os.environ\u001b[1m[\u001b[0m“WANDB_DISABLED”\u001b[1m]\u001b[0m = “true”                                                            \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m            \u001b[1;91m▲\u001b[0m                                                                                     \u001b[91m│\u001b[0m\n",
       "\u001b[91m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mSyntaxError: \u001b[0minvalid character \u001b[32m'“'\u001b[0m \u001b[1m(\u001b[0mU+201C\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[“WANDB_DISABLED”] = “true”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ecb72a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-09T17:27:33.818091Z",
     "iopub.status.busy": "2023-08-09T17:27:33.817654Z",
     "iopub.status.idle": "2023-08-09T17:27:33.824877Z",
     "shell.execute_reply": "2023-08-09T17:27:33.823665Z",
     "shell.execute_reply.started": "2023-08-09T17:27:33.818056Z"
    },
    "id": "jFp7fxqNE9xx",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets.utils.logging import disable_progress_bar\n",
    "from transformers import logging\n",
    "\n",
    "\n",
    "disable_progress_bar()\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec91539",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-09T17:27:44.002558Z",
     "iopub.status.busy": "2023-08-09T17:27:44.002088Z",
     "iopub.status.idle": "2023-08-09T17:27:44.008671Z",
     "shell.execute_reply": "2023-08-09T17:27:44.007622Z",
     "shell.execute_reply.started": "2023-08-09T17:27:44.002518Z"
    },
    "id": "kN_UjOK836FV",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "directory = \"/kaggle/input/amazon-with-translated\"\n",
    "# directory = \"/content/drive/MyDrive/MSc/NLP/nlp-project\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedf79fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-09T17:27:51.593648Z",
     "iopub.status.busy": "2023-08-09T17:27:51.592920Z",
     "iopub.status.idle": "2023-08-09T17:27:51.598865Z",
     "shell.execute_reply": "2023-08-09T17:27:51.597783Z",
     "shell.execute_reply.started": "2023-08-09T17:27:51.593612Z"
    },
    "id": "xzo4NgBBmLJB",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_path = f\"{directory}/train.csv\"\n",
    "test_path = f\"{directory}/test.csv\"\n",
    "valid_path = f\"{directory}/valid.csv\"\n",
    "translated_test_path = f\"{directory}/amazon_translated_body_and_title_with_originals_all_stars.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b602a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-09T17:27:56.244492Z",
     "iopub.status.busy": "2023-08-09T17:27:56.243788Z",
     "iopub.status.idle": "2023-08-09T17:28:10.620485Z",
     "shell.execute_reply": "2023-08-09T17:28:10.619375Z",
     "shell.execute_reply.started": "2023-08-09T17:27:56.244454Z"
    },
    "id": "_jq8AL2SmLJB",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)\n",
    "valid_df = pd.read_csv(valid_path)\n",
    "translated_test_df = pd.read_csv(translated_test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c88c31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-09T17:28:48.273786Z",
     "iopub.status.busy": "2023-08-09T17:28:48.273034Z",
     "iopub.status.idle": "2023-08-09T17:28:48.292021Z",
     "shell.execute_reply": "2023-08-09T17:28:48.283036Z",
     "shell.execute_reply.started": "2023-08-09T17:28:48.273747Z"
    },
    "id": "FLKCiae-6WxA",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "translated_test_df.rename(columns={\"review_body\": \"review_body_original\", \"review_title\": \"review_title_original\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41a8bed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-09T17:28:50.456444Z",
     "iopub.status.busy": "2023-08-09T17:28:50.455464Z",
     "iopub.status.idle": "2023-08-09T17:28:50.462483Z",
     "shell.execute_reply": "2023-08-09T17:28:50.461293Z",
     "shell.execute_reply.started": "2023-08-09T17:28:50.456404Z"
    },
    "id": "px5xhV2k68sc",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "translated_test_df.rename(columns={\"translated_body\": \"review_body\", \"translated_title\": \"review_title\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7980d521",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-09T17:28:52.258672Z",
     "iopub.status.busy": "2023-08-09T17:28:52.258049Z",
     "iopub.status.idle": "2023-08-09T17:28:52.348185Z",
     "shell.execute_reply": "2023-08-09T17:28:52.346871Z",
     "shell.execute_reply.started": "2023-08-09T17:28:52.258621Z"
    },
    "id": "ljcytX1KmLJB",
    "outputId": "c62fa29e-01d3-4922-eecf-d21d2a0b003a",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1ff086",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-09T17:28:54.866039Z",
     "iopub.status.busy": "2023-08-09T17:28:54.865545Z",
     "iopub.status.idle": "2023-08-09T17:28:54.883166Z",
     "shell.execute_reply": "2023-08-09T17:28:54.881929Z",
     "shell.execute_reply.started": "2023-08-09T17:28:54.865998Z"
    },
    "id": "eqXdSpJCmLJC",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SEED = 111\n",
    "\n",
    "# Set the random seed for Python to SEED\n",
    "random.seed(SEED)\n",
    "\n",
    "# Set the random seed for numpy to SEED\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Set the random seed for torch to SEED\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ec2b96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-09T17:28:57.424378Z",
     "iopub.status.busy": "2023-08-09T17:28:57.423510Z",
     "iopub.status.idle": "2023-08-09T17:28:58.257477Z",
     "shell.execute_reply": "2023-08-09T17:28:58.256531Z",
     "shell.execute_reply.started": "2023-08-09T17:28:57.424339Z"
    },
    "id": "ti8lptcdmLJC",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def verbose_print(msg, verbose=False):\n",
    "    if verbose:\n",
    "        print(msg)\n",
    "\n",
    "\n",
    "def drop_data(df, stars, languages, columns_to_drop):\n",
    "    df = df[df[\"stars\"].isin(stars)]\n",
    "    df = df[df[\"language\"].isin(languages)]\n",
    "    if len(columns_to_drop) > 0:\n",
    "        df.drop(columns=columns_to_drop, inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def prepare_data(\n",
    "    train, test, valid, columns_to_drop, stars=[1, 2, 3, 4], languages=[\"en\"]\n",
    "):\n",
    "    train = drop_data(train, stars, languages, columns_to_drop)\n",
    "    test = drop_data(test, stars, languages, columns_to_drop)\n",
    "    valid = drop_data(valid, stars, languages, columns_to_drop)\n",
    "\n",
    "    return train, test, valid\n",
    "\n",
    "\n",
    "def reduce_dataset(df, stars, languages, num_of_rows_to_drop, verbose=False):\n",
    "    for lang in languages:\n",
    "        for star in stars:\n",
    "            verbose_print(f\"Language: {lang}, Stars: {star}\", verbose)\n",
    "            verbose_print(\n",
    "                f'Number of rows before: {len(df[(df[\"language\"] == lang) & (df[\"stars\"] == star)])}',\n",
    "                verbose,\n",
    "            )\n",
    "            random_indices = np.random.choice(\n",
    "                df[(df[\"language\"] == lang) & (df[\"stars\"] == star)].index,\n",
    "                num_of_rows_to_drop,\n",
    "                replace=False,\n",
    "            )\n",
    "            df.drop(index=random_indices, inplace=True)\n",
    "            verbose_print(\n",
    "                f'Number of rows after: {len(df[(df[\"language\"] == lang) & (df[\"stars\"] == star)])}',\n",
    "                verbose,\n",
    "            )\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def replace_mapping(df, label, mapping):\n",
    "    for k, v in mapping.items():\n",
    "        df[label].replace(k, v, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def prepare_truncation(data_df, tokenizer, m, n):\n",
    "    for i, r in tqdm(data_df.iterrows(), total=len(data_df), desc=\"Processing reviews\"):\n",
    "        tokenized_row = tokenizer.tokenize(r[\"review_body\"])\n",
    "        if len(tokenized_row) > m + n:\n",
    "            data_df.loc[i, \"review_body\"] = tokenizer.convert_tokens_to_string(\n",
    "                tokenized_row[:m] + tokenized_row[-n:]\n",
    "            )\n",
    "\n",
    "    return data_df\n",
    "\n",
    "\n",
    "def print_using_tabulate(data):\n",
    "    table_data = []\n",
    "    for key, values in data.items():\n",
    "        if key != \"macro avg\" and key != \"weighted avg\":\n",
    "            if isinstance(values, dict):\n",
    "                row = [\n",
    "                    key,\n",
    "                    values[\"precision\"],\n",
    "                    values[\"recall\"],\n",
    "                    values[\"f1-score\"],\n",
    "                    values[\"support\"],\n",
    "                ]\n",
    "                table_data.append(row)\n",
    "\n",
    "    # Print the classification report using tabulate\n",
    "    headers = [\"Class\", \"Precision\", \"Recall\", \"F1-Score\", \"Support\"]\n",
    "    m_table = tabulate(table_data, headers=headers, tablefmt=\"psql\", floatfmt=\".4f\")\n",
    "    print(m_table)\n",
    "\n",
    "\n",
    "def eval_model(trainer, test_set, target_names, label):\n",
    "    predictions = trainer.predict(test_set)\n",
    "    predicted_labels = predictions.predictions.argmax(axis=1)\n",
    "    ground_truth_labels = test_set[label]\n",
    "    classification_reports = classification_report(\n",
    "        ground_truth_labels,\n",
    "        predicted_labels,\n",
    "        target_names=target_names,\n",
    "        output_dict=True,\n",
    "    )\n",
    "    print_using_tabulate(classification_reports)\n",
    "    print(\"\\n\\n\\n\")\n",
    "\n",
    "\n",
    "load_accuracy = evaluate.load(\"accuracy\")\n",
    "load_f1 = evaluate.load(\"f1\")\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    accuracy = load_accuracy.compute(predictions=predictions, references=labels)[\n",
    "        \"accuracy\"\n",
    "    ]\n",
    "    f1 = load_f1.compute(\n",
    "        predictions=predictions, references=labels, average=\"weighted\"\n",
    "    )[\"f1\"]\n",
    "    return {\"accuracy\": accuracy, \"f1\": f1}\n",
    "\n",
    "\n",
    "# Preprocess function with labels\n",
    "def preprocess_function(examples):\n",
    "    inputs = tokenizer(examples[\"review_body\"], truncation=True)\n",
    "    inputs[\"labels\"] = examples[\"stars\"]\n",
    "    return inputs\n",
    "\n",
    "\n",
    "def train_model(\n",
    "    model_name,\n",
    "    num_of_labels,\n",
    "    dataset,\n",
    "    tokenizer,\n",
    "    path_to_save,\n",
    "    epochs=1,\n",
    "    disable_tqdm=False,\n",
    "):\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=path_to_save,\n",
    "        warmup_steps=10000,\n",
    "        optim=\"adamw_torch\",\n",
    "        num_train_epochs=epochs,\n",
    "        weight_decay=1e-4,\n",
    "        evaluation_strategy=IntervalStrategy.EPOCH,\n",
    "        save_strategy=IntervalStrategy.EPOCH,\n",
    "        metric_for_best_model=\"f1\",\n",
    "        save_total_limit=1,\n",
    "        disable_tqdm=disable_tqdm,\n",
    "    )\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name, num_labels=num_of_labels\n",
    "    )\n",
    "    tokenized_train = dataset[\"train\"].map(preprocess_function, batched=True)\n",
    "    tokenized_validation = dataset[\"validation\"].map(preprocess_function, batched=True)\n",
    "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_train,\n",
    "        eval_dataset=tokenized_validation,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    return trainer\n",
    "\n",
    "\n",
    "def prepare_dataset(train_df, test_df, valid_df, translated_df):\n",
    "    train_ds = Dataset.from_pandas(train_df)\n",
    "    test_ds = Dataset.from_pandas(test_df)\n",
    "    valid_ds = Dataset.from_pandas(valid_df)\n",
    "    translated_ds = Dataset.from_pandas(translated_df)\n",
    "\n",
    "    dataset = DatasetDict()\n",
    "\n",
    "    dataset[\"train\"] = train_ds\n",
    "    dataset[\"validation\"] = valid_ds\n",
    "    dataset[\"test\"] = test_ds\n",
    "    dataset[\"translated\"] = translated_ds\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def run_and_eval(\n",
    "    train_df,\n",
    "    test_df,\n",
    "    valid_df,\n",
    "    stars,\n",
    "    languages,\n",
    "    columns_to_drop,\n",
    "    rows_to_drop,\n",
    "    label,\n",
    "    mapping,\n",
    "    model_name,\n",
    "    num_of_labels,\n",
    "    M,\n",
    "    N,\n",
    "    label_names,\n",
    "    verbose=False,\n",
    "    epochs=1,\n",
    "    disable_tqdm=True):\n",
    "\n",
    "    train, test, val = prepare_data(\n",
    "        train_df, test_df, valid_df, columns_to_drop, stars, languages\n",
    "    )\n",
    "    train = reduce_dataset(train, stars, languages, rows_to_drop, verbose)\n",
    "    train = replace_mapping(train, label, mapping)\n",
    "    test = replace_mapping(test, label, mapping)\n",
    "    val = replace_mapping(val, label, mapping)\n",
    "\n",
    "    translated = drop_data(translated_test_df, stars, [\"de\", \"es\", \"fr\"], [])\n",
    "    translated = replace_mapping(translated, label, mapping)\n",
    "\n",
    "    global tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, num_labels=num_of_labels)\n",
    "    train = prepare_truncation(train, tokenizer, M, N)\n",
    "    test = prepare_truncation(test, tokenizer, M, N)\n",
    "    val = prepare_truncation(val, tokenizer, M, N)\n",
    "    translated = prepare_truncation(translated, tokenizer, M, N)\n",
    "\n",
    "    dataset = prepare_dataset(train, test, val, translated)\n",
    "    trainer = train_model(\n",
    "        model_name,\n",
    "        num_of_labels,\n",
    "        dataset,\n",
    "        tokenizer,\n",
    "        f\"./{model_name}_labels_{num_of_labels}_M_{M}_N_{N}\",\n",
    "        epochs=epochs,\n",
    "        disable_tqdm=disable_tqdm\n",
    "    )\n",
    "\n",
    "    print(f\"Results for model: {model_name}, M = {M}, N = {N}\")\n",
    "    print(\"English test set results\")\n",
    "    tokenized_train = dataset[\"test\"].map(preprocess_function, batched=True)\n",
    "    eval_model(trainer, tokenized_train, label_names, label)\n",
    "    print()\n",
    "    print(\"Translated to English set results\")\n",
    "    tokenized_train = dataset[\"translated\"].map(preprocess_function, batched=True)\n",
    "    eval_model(trainer, tokenized_train, label_names, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6845d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-09T17:29:04.464424Z",
     "iopub.status.busy": "2023-08-09T17:29:04.463957Z",
     "iopub.status.idle": "2023-08-09T17:29:04.470632Z",
     "shell.execute_reply": "2023-08-09T17:29:04.469548Z",
     "shell.execute_reply.started": "2023-08-09T17:29:04.464382Z"
    },
    "id": "YKnwdYzLmLJD",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "columns_to_drop = ['review_id', 'product_id', 'reviewer_id', 'product_category']\n",
    "tokenizer = None\n",
    "rows_to_drop = 30000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2dd1f4b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "**BERT CASED**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f50f21",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "**Two labels with Neutral; N=128, M=382; overall 510 tokens**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf59798",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-09T17:29:12.266445Z",
     "iopub.status.busy": "2023-08-09T17:29:12.266066Z",
     "iopub.status.idle": "2023-08-09T17:46:28.568263Z",
     "shell.execute_reply": "2023-08-09T17:46:28.567013Z",
     "shell.execute_reply.started": "2023-08-09T17:29:12.266414Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = \"bert-base-cased\"\n",
    "stars = [1, 2, 3, 4, 5]\n",
    "languages = [\"en\"]\n",
    "mapping = {1: 0, 2: 0, 3: 0, 4: 1, 5: 1}\n",
    "N = 128\n",
    "M = 382\n",
    "num_of_labels = 2\n",
    "label = \"stars\"\n",
    "label_names = [\"Negative\", \"Positive\"]\n",
    "epochs = 1\n",
    "\n",
    "run_and_eval(\n",
    "    train_df,\n",
    "    test_df,\n",
    "    valid_df,\n",
    "    stars,\n",
    "    languages,\n",
    "    columns_to_drop,\n",
    "    rows_to_drop,\n",
    "    label,\n",
    "    mapping,\n",
    "    model_name,\n",
    "    num_of_labels,\n",
    "    M,\n",
    "    N,\n",
    "    label_names,\n",
    "    False,\n",
    "    epochs,\n",
    "    False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bfb3bc",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "**Two labels with Neutral; N=64, M=64; overall 128 tokens**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa561035",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "N = 64\n",
    "M = 64\n",
    "\n",
    "run_and_eval(\n",
    "    train_df,\n",
    "    test_df,\n",
    "    valid_df,\n",
    "    stars,\n",
    "    languages,\n",
    "    columns_to_drop,\n",
    "    rows_to_drop,\n",
    "    label,\n",
    "    mapping,\n",
    "    model_name,\n",
    "    num_of_labels,\n",
    "    M,\n",
    "    N,\n",
    "    label_names,\n",
    "    False,\n",
    "    epochs,\n",
    "    False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec530e93",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "**Two labels with Neutral; N=510, M=0; overall 510 tokens**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27676cb4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "N = 510\n",
    "M = 0\n",
    "\n",
    "run_and_eval(\n",
    "    train_df,\n",
    "    test_df,\n",
    "    valid_df,\n",
    "    stars,\n",
    "    languages,\n",
    "    columns_to_drop,\n",
    "    rows_to_drop,\n",
    "    label,\n",
    "    mapping,\n",
    "    model_name,\n",
    "    num_of_labels,\n",
    "    M,\n",
    "    N,\n",
    "    label_names,\n",
    "    False,\n",
    "    epochs,\n",
    "    False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cce5483",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "**Two labels with Neutral; N=0, M=510; overall 510 tokens**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d73c62",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "N = 0\n",
    "M = 510\n",
    "\n",
    "run_and_eval(\n",
    "    train_df,\n",
    "    test_df,\n",
    "    valid_df,\n",
    "    stars,\n",
    "    languages,\n",
    "    columns_to_drop,\n",
    "    rows_to_drop,\n",
    "    label,\n",
    "    mapping,\n",
    "    model_name,\n",
    "    num_of_labels,\n",
    "    M,\n",
    "    N,\n",
    "    label_names,\n",
    "    False,\n",
    "    epochs,\n",
    "    False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9417def",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "**XLNET 2 labels with Neutrals**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b064a031",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = \"xlnet-base-cased\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f85567d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "**Two labels with Neutral; N=128, M=382; overall 510 tokens**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a025b2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "N = 128\n",
    "M = 382\n",
    "\n",
    "run_and_eval(\n",
    "    train_df,\n",
    "    test_df,\n",
    "    valid_df,\n",
    "    stars,\n",
    "    languages,\n",
    "    columns_to_drop,\n",
    "    rows_to_drop,\n",
    "    label,\n",
    "    mapping,\n",
    "    model_name,\n",
    "    num_of_labels,\n",
    "    M,\n",
    "    N,\n",
    "    label_names,\n",
    "    False,\n",
    "    epochs,\n",
    "    False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ea77f8",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "**Two labels with Neutral; N=64, M=64; overall 128 tokens**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc11bbb",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "N = 64\n",
    "M = 64\n",
    "\n",
    "run_and_eval(\n",
    "    train_df,\n",
    "    test_df,\n",
    "    valid_df,\n",
    "    stars,\n",
    "    languages,\n",
    "    columns_to_drop,\n",
    "    rows_to_drop,\n",
    "    label,\n",
    "    mapping,\n",
    "    model_name,\n",
    "    num_of_labels,\n",
    "    M,\n",
    "    N,\n",
    "    label_names,\n",
    "    False,\n",
    "    epochs,\n",
    "    False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7f99b0",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "**Two labels with Neutral; N=510, M=0; overall 510 tokens**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25438298",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "N = 510\n",
    "M = 0\n",
    "\n",
    "run_and_eval(\n",
    "    train_df,\n",
    "    test_df,\n",
    "    valid_df,\n",
    "    stars,\n",
    "    languages,\n",
    "    columns_to_drop,\n",
    "    rows_to_drop,\n",
    "    label,\n",
    "    mapping,\n",
    "    model_name,\n",
    "    num_of_labels,\n",
    "    M,\n",
    "    N,\n",
    "    label_names,\n",
    "    False,\n",
    "    epochs,\n",
    "    False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727c8d9d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "**Two labels with Neutral; N=0, M=510; overall 510 tokens**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f40f1a5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "N = 0\n",
    "M = 510\n",
    "\n",
    "run_and_eval(\n",
    "    train_df,\n",
    "    test_df,\n",
    "    valid_df,\n",
    "    stars,\n",
    "    languages,\n",
    "    columns_to_drop,\n",
    "    rows_to_drop,\n",
    "    label,\n",
    "    mapping,\n",
    "    model_name,\n",
    "    num_of_labels,\n",
    "    M,\n",
    "    N,\n",
    "    label_names,\n",
    "    False,\n",
    "    epochs,\n",
    "    False,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 75.740298,
   "end_time": "2023-08-09T17:55:11.008571",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-08-09T17:53:55.268273",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
